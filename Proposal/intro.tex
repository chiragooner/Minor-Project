\pagenumbering{roman}
	\addcontentsline{toc}{section}{Abstract}
		\large
			\chapter*{Abstract}
		\normalsize
		
		Lip reading is the task of decoding text by interpreting the movements, shape and other spatiotemporal facial features from  a recorded video clip of a speaker. It invloves mainly studying the movements and configurations in and around the lip area of a speaker. It can be especially useful for people with speech and hearing disabilities so that they can better convey their message to a listener. Besides that, it can be used as a means of comprehending or captioning spoken media from videos recorded in situtations where sound may be difficult to perceive, such as in noisy environments or when the speaker is at a distance.In recent years, technological advancements, particularly in the field of computer vision and machine learning, have led to the development of automated lip reading systems. These systems use algorithms and models to analyze lip movements and convert them into text, providing potential applications in areas such as assistive technologies, human-computer interaction, and surveillance. This proposal outlines a comprehensive research project aimed at advancing the field of lip reading through the integration of Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks. The proposed hybrid architecture leverages the strengths of both CNNs and LSTMs to enhance the accuracy and efficiency of lip reading systems, addressing the inherent challenges in visual speech recognition.The proposed hybrid architecture will be trained on a comprehensive dataset, including diverse speakers, languages, and environmental conditions, to ensure robustness and generalization. Fine-tuning mechanisms will be implemented to optimize model parameters and improve its adaptability to various lip reading scenarios.We researched on usage of both audio-visual data as input but for implementation of such models would increase the complexity of our project so we have proposed the usage of only visual data as input for timely completion of our project.
				
	\tableofcontents
		
	\addcontentsline{toc}{section}{List of Figures}
	\listoffigures
		
	\pagebreak
	
	
		\addcontentsline{toc}{section}{List of Symbols and Abbreviation}
		\Large
			\begingroup
				\let\clearpage\relax
				\chapter*{List of Symbols and Abbreviation}
			\endgroup
		\normalsize
		\begin{tabular}{p{1in}p{3in}}
		 CNN & Convolutional Neural Networks\\
		 ASR & Automatic Speech Recognition\\
		 ALR & Automatic Lipreading\\
		 Bi-GRU & Bi directional Gated recurrent unit\\
		 RNN & Recurrent Neural Network\\
		 SAT & Speaker Adaptive Training
		 
		\end{tabular}
		\pagebreak